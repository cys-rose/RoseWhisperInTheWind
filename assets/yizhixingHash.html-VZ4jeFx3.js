import{_ as a,c as s,b as t,o as h}from"./app-DFDql4E9.js";const i="/RoseWhisperInTheWind/assets/%E4%B8%80%E8%87%B4%E6%80%A7Hash-BtPZ1sRy.png",n="/RoseWhisperInTheWind/assets/%E4%B8%80%E8%87%B4%E6%80%A7Hash%E6%89%A9%E5%AE%B9-D_7Dlbt_.png",o="/RoseWhisperInTheWind/assets/%E8%BE%B9%E7%95%8C%E8%B4%9F%E8%BD%BD%E4%B8%80%E8%87%B4%E6%80%A7Hash-BKIRSEK0.png",r={};function l(p,e){return h(),s("div",null,e[0]||(e[0]=[t('<h1 id="一致性-hash" tabindex="-1"><a class="header-anchor" href="#一致性-hash"><span>一致性 Hash</span></a></h1><p>大家设想一下如果在 Redis Cluster 集群中，如果我们仅仅是根据 key 算出 hash 值然后根据集群中 master 数量取模分配时会有什么问题？</p><p>在新增节点和删除节点时，导致原缓存失效。因为当你根据 key 去存放到不同的节点时，假设原来是<code>%3</code>存的（原有 3 个节点），现在减少了一个节点所以得按照<code>%2</code>去找对应的服务器，这样的话原来的 key 就会失效，导致大量缓存 key 过期（雪崩问题） 虽然 Redis Cluster 采用的是哈希槽解决的，但借其引出我们的主题，不过分吧嘿嘿！</p><h2 id="一致性-hash-原理" tabindex="-1"><a class="header-anchor" href="#一致性-hash-原理"><span>一致性 Hash 原理</span></a></h2><ol><li>使用 Hash 环（2^32 长度）</li><li>将服务器 ip 映射到 Hash 环上<br> hash（服务器 ip）% 2^32</li><li>将对象 key 映射到 Hash 环上 hash（key）% 2^32 与上面的不是同一个 Hash 算法</li><li>对于每个 key 采用顺时针的方式找到其所属的服务器上 <img src="'+i+'" alt="一致性Hash" loading="lazy"></li><li>如果增加服务器，只需要将一部分 key 重新分配。减少服务器也同理！（按照顺时针分配） <img src="'+n+'" alt="一致性Hash扩容" loading="lazy"></li></ol><h2 id="存在的问题" tabindex="-1"><a class="header-anchor" href="#存在的问题"><span>存在的问题</span></a></h2><p>节点分配不均！！！节点分配不均！！！节点分配不均！！！怎么办？想想为什么不均匀？答：<code>服务器数量太少</code>，导致每个服务器管理的范围太宽了。那怎么办？还不能添加服务器，那就给每一个服务器分配多个虚拟节点，然后散布在 Hash 环上，根据 key 先找到虚拟节点，再对应到真是服务器上。并且虚拟节点设置的越多，分配地就越均匀。</p><h2 id="含边界负载的一致性-hash" tabindex="-1"><a class="header-anchor" href="#含边界负载的一致性-hash"><span>含边界负载的一致性 Hash</span></a></h2><figure><img src="'+o+'" alt="含边界负载的一致性 Hash" tabindex="0" loading="lazy"><figcaption>含边界负载的一致性 Hash</figcaption></figure><h2 id="声明" tabindex="-1"><a class="header-anchor" href="#声明"><span>声明</span></a></h2><p>本篇文章参考学习于 <code>https://mp.weixin.qq.com/s/WTz1KA9kOGrqFVTtALJzjQ</code>如果大家想看看一致性 Hash 算法的代码实现请学习原文。</p>',11)]))}const d=a(r,[["render",l],["__file","yizhixingHash.html.vue"]]),m=JSON.parse('{"path":"/anything/yizhixingHash.html","title":"一致性 Hash","lang":"zh-CN","frontmatter":{"description":"一致性 Hash 大家设想一下如果在 Redis Cluster 集群中，如果我们仅仅是根据 key 算出 hash 值然后根据集群中 master 数量取模分配时会有什么问题？ 在新增节点和删除节点时，导致原缓存失效。因为当你根据 key 去存放到不同的节点时，假设原来是%3存的（原有 3 个节点），现在减少了一个节点所以得按照%2去找对应的服务器，...","head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/RoseWhisperInTheWind/anything/yizhixingHash.html"}],["meta",{"property":"og:site_name","content":"风中玫瑰的低语"}],["meta",{"property":"og:title","content":"一致性 Hash"}],["meta",{"property":"og:description","content":"一致性 Hash 大家设想一下如果在 Redis Cluster 集群中，如果我们仅仅是根据 key 算出 hash 值然后根据集群中 master 数量取模分配时会有什么问题？ 在新增节点和删除节点时，导致原缓存失效。因为当你根据 key 去存放到不同的节点时，假设原来是%3存的（原有 3 个节点），现在减少了一个节点所以得按照%2去找对应的服务器，..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-01-20T08:42:04.000Z"}],["meta",{"property":"article:modified_time","content":"2025-01-20T08:42:04.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"一致性 Hash\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-01-20T08:42:04.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Rose\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"一致性 Hash 原理","slug":"一致性-hash-原理","link":"#一致性-hash-原理","children":[]},{"level":2,"title":"存在的问题","slug":"存在的问题","link":"#存在的问题","children":[]},{"level":2,"title":"含边界负载的一致性 Hash","slug":"含边界负载的一致性-hash","link":"#含边界负载的一致性-hash","children":[]},{"level":2,"title":"声明","slug":"声明","link":"#声明","children":[]}],"git":{"createdTime":1736928894000,"updatedTime":1737362524000,"contributors":[{"name":"Rose","email":"2677596161@qq.com","commits":2}]},"readingTime":{"minutes":1.73,"words":520},"filePathRelative":"anything/yizhixingHash.md","localizedDate":"2025年1月15日","excerpt":"\\n<p>大家设想一下如果在 Redis Cluster 集群中，如果我们仅仅是根据 key 算出 hash 值然后根据集群中 master 数量取模分配时会有什么问题？</p>\\n<p>在新增节点和删除节点时，导致原缓存失效。因为当你根据 key 去存放到不同的节点时，假设原来是<code>%3</code>存的（原有 3 个节点），现在减少了一个节点所以得按照<code>%2</code>去找对应的服务器，这样的话原来的 key 就会失效，导致大量缓存 key 过期（雪崩问题）\\n虽然 Redis Cluster 采用的是哈希槽解决的，但借其引出我们的主题，不过分吧嘿嘿！</p>\\n<h2>一致性 Hash 原理</h2>","autoDesc":true}');export{d as comp,m as data};
